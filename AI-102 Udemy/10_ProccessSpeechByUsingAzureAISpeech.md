# Process speech by using Azure AI Speech

## Implement text-to-speech

Prosody -> speech and intonation in human-like language.

**Customizable AI (neural) voices.**

Non-neural voices will be retired in 2024.

![alt text](image-161.png)

The speech API can run On-Prem!

![alt text](image-162.png)

![alt text](image-163.png)

![alt text](image-164.png)

![alt text](image-165.png)

## Implement speech-to-text

Common for subtitles, transcrisps...

![alt text](image-166.png)

For example Azure, AI-102, .NET, etc... Technical-specific language.

![alt text](image-167.png)

![alt text](image-168.png)

## Speech Synthesis Markup Language (SSML)

![alt text](image-169.png)

![alt text](image-170.png)

![alt text](image-171.png)

We have tons of options:

![alt text](image-172.png)

Also styles (jobs, emotions, etc...):

![alt text](image-173.png)

Angry/softness:

![alt text](image-174.png)

Also a role (age):

![alt text](image-175.png)

Clues on the shape of mouth. Useful for 2D/3D avatars!

![alt text](image-176.png)

![alt text](image-177.png)

## Implement intent recognition

Intent is something the user wants to do.

![alt text](image-178.png)

![alt text](image-179.png)

![alt text](image-180.png)

![alt text](image-181.png)

Two ways:

- Pattern matching. Recognize certain words and trigger the intention. Recommended for first and simple uses.
- Conversational Language Understanding (CLU). The user speech is transcribed and then the intention is extracted with the Language API.

About CLU:

![alt text](image-182.png)

150+ examples needed.

## Implement keyword recognition

![alt text](image-183.png)

**Keyword recognition on-device!**

![alt text](image-185.png)

![alt text](image-186.png)

Continuos audio on .NET:

![alt text](image-187.png)

![alt text](image-188.png)

![alt text](image-189.png)
